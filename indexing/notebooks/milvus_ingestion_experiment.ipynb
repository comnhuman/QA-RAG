{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37701fb4",
   "metadata": {},
   "source": [
    "# Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f56b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"../huggingface_data\"\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain_docling import DoclingLoader\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "EXPORT_TYPE = \"doc_chunks\"\n",
    "EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-8B\"\n",
    "CHUNKER = HybridChunker(tokenizer=EMBED_MODEL_ID, max_tokens=1000)\n",
    "\n",
    "all_files = [\n",
    "    f for f in DATA_DIR.rglob(\"*\")\n",
    "    if f.is_file() and not f.name.startswith(\".\")\n",
    "]\n",
    "\n",
    "# all_files = all_files[:3]\n",
    "\n",
    "all_docs = []\n",
    "for file_path in all_files:\n",
    "    try:\n",
    "        loader = DoclingLoader(\n",
    "            file_path=str(file_path),\n",
    "            export_type=EXPORT_TYPE,\n",
    "            chunker=CHUNKER,\n",
    "        )\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)\n",
    "        print(f\"{file_path.name} → {len(docs)} chunks 생성 완료\")\n",
    "    except Exception as e:\n",
    "        print(f\"{file_path.name} 처리 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b4c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be2269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d409c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def normalize_dedup_convert_inplace(docs: list[Document]) -> None:\n",
    "    seen_index: dict[int, int] = {}   # pk -> 첫 등장 인덱스\n",
    "    remove_indices: list[int] = []\n",
    "\n",
    "    for i in range(len(docs)):\n",
    "        doc = docs[i]\n",
    "        md = getattr(doc, \"metadata\", {}) or {}\n",
    "\n",
    "        src = md.get(\"source\")\n",
    "        if isinstance(src, list):\n",
    "            src_list = [s for s in src if s is not None]\n",
    "        elif src is None:\n",
    "            src_list = []\n",
    "        else:\n",
    "            src_list = [src]\n",
    "\n",
    "        pk = md.get(\"pk\")\n",
    "        if pk is None:\n",
    "            hash_val = hashlib.sha256(doc.page_content.encode(\"utf-8\")).hexdigest()\n",
    "            pk = int(hash_val, 16) % (1 << 63)\n",
    "\n",
    "        if pk not in seen_index:\n",
    "            docs[i] = {\n",
    "                \"text\": doc.page_content,\n",
    "                \"pk\": pk,\n",
    "                \"source\": src_list,\n",
    "            }\n",
    "            seen_index[pk] = i\n",
    "        else:\n",
    "            base = docs[seen_index[pk]]       \n",
    "            base_src = base.get(\"source\", [])\n",
    "            for s in src_list:\n",
    "                if s not in base_src:\n",
    "                    base_src.append(s)\n",
    "            base[\"source\"] = base_src\n",
    "\n",
    "            remove_indices.append(i)\n",
    "\n",
    "    for idx in reversed(remove_indices):\n",
    "        del docs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_dedup_convert_inplace(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db32c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94469aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fadfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Iterable\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_URL = \"http://127.0.0.1:9804/v1\"\n",
    "EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-4B\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=OPENAI_URL,\n",
    ")\n",
    "\n",
    "def _chunks(seq: list[dict[str, Any]], size: int) -> Iterable[list[dict[str, Any]]]:\n",
    "    for i in range(0, len(seq), size):\n",
    "        yield seq[i:i+size]\n",
    "\n",
    "def embed_docs_inplace(\n",
    "    docs: list[dict[str, Any]],\n",
    "    *,\n",
    "    model: str = EMBED_MODEL_ID,\n",
    "    batch_size: int = 128,\n",
    "    text_key: str = \"text\",\n",
    "    vector_key: str = \"vector\",\n",
    "    max_retries: int = 5,\n",
    "    backoff_base: float = 1.5,\n",
    ") -> None:\n",
    "    batches = []\n",
    "    for batch in _chunks(docs, batch_size):\n",
    "        to_process = [(i, d) for i, d in enumerate(batch)]\n",
    "\n",
    "        if not to_process:\n",
    "            continue\n",
    "\n",
    "        inputs = []\n",
    "        idx_map = []\n",
    "        for j, d in to_process:\n",
    "            text = d.get(text_key)\n",
    "            if not isinstance(text, str) or not text.strip():\n",
    "                d[vector_key] = None\n",
    "                continue\n",
    "            inputs.append(text)\n",
    "            idx_map.append(j)\n",
    "\n",
    "        if not inputs:\n",
    "            continue\n",
    "\n",
    "        attempt = 0\n",
    "        while True:\n",
    "            try:\n",
    "                resp = client.embeddings.create(model=model, input=inputs)\n",
    "                for k, item in enumerate(resp.data):\n",
    "                    batch[idx_map[k]][vector_key] = item.embedding\n",
    "                break\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                if attempt > max_retries:\n",
    "                    for j in idx_map:\n",
    "                        batch[j][vector_key] = None\n",
    "                    break\n",
    "                time.sleep(backoff_base ** attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_docs_inplace(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8666463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "URI = \"http://localhost:19530\"\n",
    "\n",
    "client = MilvusClient(\n",
    "    uri=URI,\n",
    "    token=\"root:Milvus\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "databases = client.list_databases()\n",
    "print(databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d7f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.use_database(\"doc_embeddings\")\n",
    "\n",
    "collection_name = \"doc_embeddings\"\n",
    "\n",
    "desc = client.describe_collection(collection_name=collection_name)\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885eb2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.use_database(\"doc_embeddings2\")\n",
    "\n",
    "collection_name = \"doc_embeddings\"\n",
    "\n",
    "desc = client.describe_collection(collection_name=collection_name)\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ed148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, Collection\n",
    "\n",
    "# 1) Milvus 접속\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    uri=\"http://127.0.0.1:19530\",\n",
    "    token=\"root:Milvus\",\n",
    "    db_name = \"doc_embeddings\"\n",
    ")\n",
    "\n",
    "# 2) 기존 컬렉션 핸들러 생성 (컬렉션 이름만 알면 됩니다)\n",
    "col = Collection(name=\"doc_embeddings\")  # ← 본인 컬렉션명\n",
    "\n",
    "# 3) 인덱스 목록 조회\n",
    "if not col.indexes:\n",
    "    print(\"인덱스가 없습니다.\")\n",
    "else:\n",
    "    for idx in col.indexes:\n",
    "        print(\"=== Index Info ===\")\n",
    "        print(\"Collection :\", col.name)\n",
    "        print(\"Field      :\", idx.field_name)        # 인덱스가 걸린 필드명 (예: 'vector')\n",
    "        print(\"Index Name :\", idx.index_name)        # 인덱스 이름 (예: 'vector')\n",
    "        print(\"Params     :\", idx.params)            # {'index_type': 'FLAT', 'metric_type': 'L2', ...}\n",
    "        # 편의 출력\n",
    "        print(\"Index Type :\", idx.params.get(\"index_type\"))\n",
    "        print(\"Metric Type:\", idx.params.get(\"metric_type\"))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, Collection\n",
    "\n",
    "# 1) Milvus 접속\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    uri=\"http://127.0.0.1:19530\",\n",
    "    token=\"root:Milvus\",\n",
    "    db_name = \"doc_embeddings2\"\n",
    ")\n",
    "\n",
    "# 2) 기존 컬렉션 핸들러 생성 (컬렉션 이름만 알면 됩니다)\n",
    "col = Collection(name=\"doc_embeddings\")  # ← 본인 컬렉션명\n",
    "\n",
    "# 3) 인덱스 목록 조회\n",
    "if not col.indexes:\n",
    "    print(\"인덱스가 없습니다.\")\n",
    "else:\n",
    "    for idx in col.indexes:\n",
    "        print(\"=== Index Info ===\")\n",
    "        print(\"Collection :\", col.name)\n",
    "        print(\"Field      :\", idx.field_name)        # 인덱스가 걸린 필드명 (예: 'vector')\n",
    "        print(\"Index Name :\", idx.index_name)        # 인덱스 이름 (예: 'vector')\n",
    "        print(\"Params     :\", idx.params)            # {'index_type': 'FLAT', 'metric_type': 'L2', ...}\n",
    "        # 편의 출력\n",
    "        print(\"Index Type :\", idx.params.get(\"index_type\"))\n",
    "        print(\"Metric Type:\", idx.params.get(\"metric_type\"))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"my_test\"\n",
    "client.create_database(db_name=db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.use_database(\"my_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a44413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, DataType\n",
    "\n",
    "schema = client.create_schema()\n",
    "\n",
    "schema.add_field(\n",
    "    field_name=\"text\",\n",
    "    datatype=DataType.VARCHAR,\n",
    "    max_length=65535,\n",
    ")\n",
    "\n",
    "schema.add_field(\n",
    "    field_name=\"pk\",\n",
    "    datatype=DataType.INT64,\n",
    "    is_primary=True,\n",
    "    auto_id=False,\n",
    ")\n",
    "\n",
    "schema.add_field(\n",
    "    field_name=\"vector\",\n",
    "    datatype=DataType.FLOAT_VECTOR,\n",
    "    dim=2560,\n",
    ")\n",
    "\n",
    "schema.add_field(\n",
    "    field_name=\"source\",\n",
    "    datatype=DataType.JSON,\n",
    "\n",
    ")\n",
    "\n",
    "index_params = client.prepare_index_params()\n",
    "\n",
    "index_params.add_index(\n",
    "    field_name=\"vector\",\n",
    "    index_name = \"vector\",\n",
    "    index_type=\"FLAT\",\n",
    "    metric_type=\"L2\"\n",
    ")\n",
    "\n",
    "if client.has_collection(\"my_test\"):\n",
    "    client.drop_collection(\"my_test\")\n",
    "client.create_collection(collection_name=\"my_test\",index_params=index_params ,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.insert(collection_name=\"my_test\", data=all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6aa670",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df43e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "URI = \"http://localhost:19530\"\n",
    "\n",
    "client = MilvusClient(\n",
    "    uri=URI,\n",
    "    token=\"root:Milvus\"\n",
    ")\n",
    "\n",
    "client.use_database(\"doc_embeddings\")\n",
    "\n",
    "def fetch_any_vector(client: MilvusClient, collection_name: str, vector_field: str = \"vector\"):\n",
    "    # pk >= 0 같은 전역 필터를 주고, limit=1로 \"아무거나\" 1개를 가져옵니다.\n",
    "    rows = client.query(\n",
    "        collection_name=collection_name,\n",
    "        filter=\"pk >= 0\",                  # 전체 범위\n",
    "        output_fields=[\"pk\", \"source\", \"text\"],\n",
    "        limit=171\n",
    "    )\n",
    "    if not rows:\n",
    "        return None\n",
    "    return rows\n",
    "\n",
    "rows = fetch_any_vector(client, \"doc_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66298496",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    print(row[\"text\"][:5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f262c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# -------------------------------\n",
    "# Milvus + Embedding + LLM 설정\n",
    "# -------------------------------\n",
    "MILVUS_URI = \"http://localhost:19530\"\n",
    "DB_NAME = \"doc_embeddings\"\n",
    "COLLECTION_NAME = \"doc_embeddings\"\n",
    "EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-4B\"\n",
    "OPENAI_URL = \"http://127.0.0.1:9804/v1\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=OPENAI_URL,\n",
    "    model=EMBED_MODEL_ID\n",
    ")\n",
    "# ② Milvus 연결\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"doc_embeddings\",\n",
    "    connection_args={\n",
    "        \"uri\": MILVUS_URI,\n",
    "        \"token\": \"root:Milvus\",\n",
    "        \"db_name\": \"doc_embeddings\"\n",
    "    },\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"L2\"\n",
    "    },\n",
    ")\n",
    "documents = vector_store.similarity_search(\"아순시온\", k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(doc.page_content[:10])\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11a761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0db8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# -------------------------------\n",
    "# Milvus + Embedding + LLM 설정\n",
    "# -------------------------------\n",
    "MILVUS_URI = \"http://localhost:19530\"\n",
    "DB_NAME = \"doc_embeddings\"\n",
    "COLLECTION_NAME = \"doc_embeddings\"\n",
    "EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-8B\"\n",
    "OPENAI_URL = \"http://127.0.0.1:9804/v1\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=OPENAI_URL,\n",
    "    model=EMBED_MODEL_ID\n",
    ")\n",
    "# ② Milvus 연결\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"doc_embeddings\",\n",
    "    connection_args={\n",
    "        \"uri\": MILVUS_URI,\n",
    "        \"token\": \"root:Milvus\",\n",
    "        \"db_name\": \"doc_embeddings\"\n",
    "    },\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"L2\"\n",
    "    },\n",
    ")\n",
    "documents = vector_store.similarity_search(\"스마트시티\", k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(doc.page_content[:10])\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# -------------------------------\n",
    "# Milvus + Embedding + LLM 설정\n",
    "# -------------------------------\n",
    "MILVUS_URI = \"http://localhost:19530\"\n",
    "DB_NAME = \"doc_embeddings\"\n",
    "COLLECTION_NAME = \"doc_embeddings\"\n",
    "EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-8B\"\n",
    "OPENAI_URL = \"http://127.0.0.1:9804/v1\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=OPENAI_URL,\n",
    "    model=EMBED_MODEL_ID\n",
    ")\n",
    "# ② Milvus 연결\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"doc_embeddings\",\n",
    "    connection_args={\n",
    "        \"uri\": MILVUS_URI,\n",
    "        \"token\": \"root:Milvus\",\n",
    "        \"db_name\": \"doc_embeddings\"\n",
    "    },\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"L2\"\n",
    "    },\n",
    ")\n",
    "documents = vector_store.similarity_search(\"스마트시티의 진행은 어떻게 되가?\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(doc.page_content[:10])\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# -------------------------------\n",
    "# Milvus + Embedding + LLM 설정\n",
    "# -------------------------------\n",
    "MILVUS_URI = \"http://localhost:19530\"\n",
    "DB_NAME = \"doc_embeddings2\"\n",
    "COLLECTION_NAME = \"doc_embeddings\"\n",
    "EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-8B\"\n",
    "OPENAI_URL = \"http://127.0.0.1:9804/v1\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=OPENAI_URL,\n",
    "    model=EMBED_MODEL_ID\n",
    ")\n",
    "# ② Milvus 연결\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"doc_embeddings\",\n",
    "    connection_args={\n",
    "        \"uri\": MILVUS_URI,\n",
    "        \"token\": \"root:Milvus\",\n",
    "        \"db_name\": DB_NAME\n",
    "    },\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"L2\"\n",
    "    },\n",
    ")\n",
    "documents = vector_store.similarity_search(\"스마트시티의 진행은 어떻게 되가?\", k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d92696",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(doc.page_content[:10])\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beee1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# -------------------------------\n",
    "# Milvus + Embedding + LLM 설정\n",
    "# -------------------------------\n",
    "MILVUS_URI = \"http://localhost:19530\"\n",
    "DB_NAME = \"doc_embeddings\"\n",
    "COLLECTION_NAME = \"doc_embeddings\"\n",
    "EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-8B\"\n",
    "OPENAI_URL = \"http://127.0.0.1:9804/v1\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=OPENAI_URL,\n",
    "    model=EMBED_MODEL_ID\n",
    ")\n",
    "# ② Milvus 연결\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"doc_embeddings\",\n",
    "    connection_args={\n",
    "        \"uri\": MILVUS_URI,\n",
    "        \"token\": \"root:Milvus\",\n",
    "        \"db_name\": \"doc_embeddings\"\n",
    "    },\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"L2\"\n",
    "    },\n",
    ")\n",
    "documents = vector_store.similarity_search(\"스마트시티의 진행은 어떻게 되가?\", k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd47430",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(doc.page_content[:10])\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "URI = \"http://localhost:19530\"\n",
    "\n",
    "client = MilvusClient(\n",
    "    uri=URI,\n",
    "    token=\"root:Milvus\"\n",
    ")\n",
    "\n",
    "client.use_database(\"doc_embeddings\")\n",
    "\n",
    "def fetch_any_vector(client: MilvusClient, collection_name: str, vector_field: str = \"vector\"):\n",
    "    # pk >= 0 같은 전역 필터를 주고, limit=1로 \"아무거나\" 1개를 가져옵니다.\n",
    "    rows = client.query(\n",
    "        collection_name=collection_name,\n",
    "        filter=\"pk >= 0\",                  # 전체 범위\n",
    "        output_fields=[\"pk\", \"source\", \"text\"],\n",
    "        limit=9999\n",
    "    )\n",
    "    if not rows:\n",
    "        return None\n",
    "    return rows\n",
    "\n",
    "rows = fetch_any_vector(client, \"doc_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf82a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    print(row[\"text\"][:10])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a207ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "URI = \"http://localhost:19530\"\n",
    "\n",
    "client = MilvusClient(\n",
    "    uri=URI,\n",
    "    token=\"root:Milvus\"\n",
    ")\n",
    "\n",
    "client.use_database(\"doc_embeddings2\")\n",
    "\n",
    "def fetch_any_vector(client: MilvusClient, collection_name: str, vector_field: str = \"vector\"):\n",
    "    # pk >= 0 같은 전역 필터를 주고, limit=1로 \"아무거나\" 1개를 가져옵니다.\n",
    "    rows = client.query(\n",
    "        collection_name=collection_name,\n",
    "        filter=\"pk >= 0\",                  # 전체 범위\n",
    "        output_fields=[\"pk\", \"source\", \"text\"],\n",
    "        limit=9999\n",
    "    )\n",
    "    if not rows:\n",
    "        return None\n",
    "    return rows\n",
    "\n",
    "rows = fetch_any_vector(client, \"doc_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3727737",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    print(row[\"text\"][:10])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# -------------------------------\n",
    "# Milvus + Embedding + LLM 설정\n",
    "# -------------------------------\n",
    "MILVUS_URI = \"http://localhost:19530\"\n",
    "DB_NAME = \"doc_embeddings\"\n",
    "COLLECTION_NAME = \"doc_embeddings\"\n",
    "EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-8B\"\n",
    "OPENAI_URL = \"http://127.0.0.1:9804/v1\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=OPENAI_URL,\n",
    "    model=EMBED_MODEL_ID\n",
    ")\n",
    "# ② Milvus 연결\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"doc_embeddings\",\n",
    "    connection_args={\n",
    "        \"uri\": MILVUS_URI,\n",
    "        \"token\": \"root:Milvus\",\n",
    "        \"db_name\": DB_NAME\n",
    "    },\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"L2\"\n",
    "    },\n",
    ")\n",
    "documents = vector_store.similarity_search(\"스마트시티의 진행은 어떻게 되가?\", k=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dde978",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(doc.page_content[:10])\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# -------------------------------\n",
    "# Milvus + Embedding + LLM 설정\n",
    "# -------------------------------\n",
    "MILVUS_URI = \"http://localhost:19530\"\n",
    "DB_NAME = \"doc_embeddings\"\n",
    "COLLECTION_NAME = \"doc_embeddings\"\n",
    "EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-8B\"\n",
    "OPENAI_URL = \"http://127.0.0.1:9804/v1\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=OPENAI_URL,\n",
    "    model=EMBED_MODEL_ID\n",
    ")\n",
    "# ② Milvus 연결\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"doc_embeddings\",\n",
    "    connection_args={\n",
    "        \"uri\": MILVUS_URI,\n",
    "        \"token\": \"root:Milvus\",\n",
    "        \"db_name\": DB_NAME\n",
    "    },\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"L2\"\n",
    "    },\n",
    ")\n",
    "documents = vector_store.similarity_search(\"스마트시티의 진행은 어떻게 되가?\", k=171)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(doc.page_content[:10])\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfefe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# -------------------------------\n",
    "# Milvus + Embedding + LLM 설정\n",
    "# -------------------------------\n",
    "MILVUS_URI = \"http://localhost:19530\"\n",
    "DB_NAME = \"doc_embeddings2\"\n",
    "COLLECTION_NAME = \"doc_embeddings\"\n",
    "EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-8B\"\n",
    "OPENAI_URL = \"http://127.0.0.1:9804/v1\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=OPENAI_URL,\n",
    "    model=EMBED_MODEL_ID\n",
    ")\n",
    "# ② Milvus 연결\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"doc_embeddings\",\n",
    "    connection_args={\n",
    "        \"uri\": MILVUS_URI,\n",
    "        \"token\": \"root:Milvus\",\n",
    "        \"db_name\": DB_NAME\n",
    "    },\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"L2\"\n",
    "    },\n",
    ")\n",
    "documents = vector_store.similarity_search(\"스마트시티의 진행은 어떻게 되가?\", k=171)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3239ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(doc.page_content[:10])\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -a ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd024eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, time, threading\n",
    "import os\n",
    "from pathlib import Path\n",
    "# from src.state import State\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "os.makedirs(\"../../huggingface_data\", exist_ok=True)\n",
    "os.environ[\"HF_HOME\"] = \"../../huggingface_data\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-8B\"\n",
    "# EMBED_MODEL_ID = \"Qwen/Qwen3-Embedding-4B\"\n",
    "OPENAI_URL = \"http://127.0.0.1:9804/v1\"\n",
    "MILVUS_URI = \"http://127.0.0.1:19530\"\n",
    "TIMEOUT_SEC = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=OPENAI_URL,\n",
    "    model=EMBED_MODEL_ID,\n",
    "    tiktoken_enabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daff2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"doc_embeddings\",\n",
    "    connection_args={\n",
    "        \"uri\": MILVUS_URI,\n",
    "        \"token\": \"root:Milvus\",\n",
    "        \"db_name\": \"doc_embeddings\"\n",
    "    },\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"L2\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b90f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"스마트 시티\"\n",
    "human_message = HumanMessage(question)\n",
    "\n",
    "\n",
    "documents = vector_store.similarity_search(question, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc237fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "File-Management-System-with-LLM (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
